{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import raycastingfunctions as rc\n",
    "import detectionfunctions as detection\n",
    "import importlib\n",
    "import gc\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common definitions\n",
    "allnumfish=[10,30,70,151]\n",
    "cmperpixel = 210/1870  # see 'images/pxpercm-conversion.pdf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import\n",
    "trials=['10-fish/0066/','/10-fish/0105/','/10-fish/0126/','30-fish/0084/','/30-fish/0115/','/30-fish/0120/','70-fish/0103/','70-fish/0107/','70-fish/0124/','150-fish/']\n",
    "framerate=30\n",
    "dt=1/framerate\n",
    "\n",
    "blind_angle = 25/360*np.pi*2  # S LeBlanc used 25 degrees, citing ref:  Diana Pita, Bret A. Moore, Luke P. Tyrrell, Esteban Fernández-Juricic, and Marı́a Ángeles Esteban. Vision in two cyprinid fish: implications for collectivebehavior. PeerJ, 3:e1113, 2015. doi: 10.7717/peerj.1113. URL https://doi.org/10.7717/peerj.1113.\n",
    "blind_start = np.pi - blind_angle/2\n",
    "binocularangle = blind_angle/2\n",
    "\n",
    "datadir = '../data/'\n",
    "detectiondir = '../detectionresults/'\n",
    "resultsdir = '../savedresults-final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process detection results and save condensed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all results together\n",
    "# processing_skipvalue = 5  # remember, I only kept every 5th one, for the detection calculations\n",
    "\n",
    "\n",
    "newimport=False\n",
    "name = 'detection-probabilistic-perfish'\n",
    "savename = 'detectionresults'\n",
    "if newimport:\n",
    "    alldetectionresults=[]\n",
    "    alldetectionresults_blind=[]\n",
    "    alldetectionresults_problow=[]\n",
    "    alldetectionresults_probhigh=[]\n",
    "    for tnum in range(len(trials)):\n",
    "        trial=trials[tnum]\n",
    "        print(trial)\n",
    "        filedir=detectiondir+trial\n",
    "        outname = filedir + name+'.pklz'\n",
    "        [pointdist,allseen,allseen_high,allseen_low,allrelangle,processing_skipvalue] = pickle.load(gzip.open(outname,'rb'))\n",
    "        # high is high blocking probability of 0.75, low is \"low blocking prob\" of 0.5\n",
    "        \n",
    "        # full blockage / full fieldd\n",
    "        alldetectionresults.append([pointdist,allseen])    \n",
    "        \n",
    "        # blind spot\n",
    "        allseen_blind = allseen.copy()\n",
    "        allseen_blind[np.abs(allrelangle)>blind_start] = 0\n",
    "        alldetectionresults_blind.append([pointdist,allseen_blind])        \n",
    "        \n",
    "        # set blind spot for incomplete blocking, and add\n",
    "        allseen_low[np.abs(allrelangle)>blind_start] = 0        \n",
    "        allseen_high[np.abs(allrelangle)>blind_start] = 0\n",
    "        alldetectionresults_problow.append([pointdist,allseen_low])\n",
    "        alldetectionresults_probhigh.append([pointdist,allseen_high])\n",
    "        \n",
    "\n",
    "    # change the data structure to one that is easier to manipulate, by putting the trials together     \n",
    "    # this is inefficient, I never updated it, but it works\n",
    "    grid_allseen = [[] for _ in range(4)]\n",
    "    grid_allseen_problow = [[] for _ in range(4)]\n",
    "    grid_allseen_probhigh = [[] for _ in range(4)]\n",
    "    grid_allseen_blind = [[] for _ in range(4)]\n",
    "    for case in range(4):\n",
    "        casesel=[range(0,3),range(3,6),range(6,9),[9]]\n",
    "        for i in range(len(casesel[case])):\n",
    "            [_,allseen] = alldetectionresults[casesel[case][i]]\n",
    "            [_,allseen_problow] = alldetectionresults_problow[casesel[case][i]]\n",
    "            [_,allseen_probhigh] = alldetectionresults_probhigh[casesel[case][i]]\n",
    "            [_,allseen_blind] = alldetectionresults_blind[casesel[case][i]]\n",
    "            if i==0:\n",
    "                grid_allseen[case] = allseen[::processing_skipvalue]\n",
    "                grid_allseen_problow[case] = allseen_problow[::processing_skipvalue]\n",
    "                grid_allseen_probhigh[case] = allseen_probhigh[::processing_skipvalue]\n",
    "                grid_allseen_blind[case] = allseen_blind[::processing_skipvalue]\n",
    "            else:\n",
    "                grid_allseen[case] = np.vstack((grid_allseen[case],allseen[::processing_skipvalue]))\n",
    "                grid_allseen_problow[case] = np.vstack((grid_allseen_problow[case],allseen_problow[::processing_skipvalue]))\n",
    "                grid_allseen_probhigh[case] = np.vstack((grid_allseen_probhigh[case],allseen_probhigh[::processing_skipvalue]))\n",
    "                grid_allseen_blind[case] = np.vstack((grid_allseen_blind[case],allseen_blind[::processing_skipvalue]))\n",
    "\n",
    "             \n",
    "\n",
    "    del alldetectionresults\n",
    "    del alldetectionresults_problow\n",
    "    del alldetectionresults_probhigh\n",
    "    del alldetectionresults_blind\n",
    "    gc.collect()\n",
    "    # now all the results are stored in these arrays\n",
    "    pickle.dump([grid_allseen, grid_allseen_problow, grid_allseen_probhigh, grid_allseen_blind,processing_skipvalue], gzip.open(resultsdir+savename+'.pklz','wb'))\n",
    "else:\n",
    "    [grid_allseen, grid_allseen_problow, grid_allseen_probhigh, grid_allseen_blind,processing_skipvalue] = pickle.load(gzip.open(resultsdir+savename+'.pklz','rb'))        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save just the means, for easy use with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_toplot = np.array([np.mean(np.mean(x,axis=-1)) for x in grid_allseen_probhigh])\n",
    "std_toplot = np.array([np.std(np.mean(x,axis=-1)) for x in grid_allseen_probhigh])\n",
    "groupdetect = [np.sum(x,axis=1) for x in grid_allseen_probhigh]\n",
    "meannum = np.array([np.mean(x) for x in groupdetect])\n",
    "stdnum = np.array([np.std(x) for x in groupdetect])\n",
    "pickle.dump([mean_toplot,std_toplot,meannum,stdnum],open(resultsdir+'ind-groupmeans.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data, and also save condensed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:  10-fish/0066/\n",
      "trial:  /10-fish/0105/\n",
      "trial:  /10-fish/0126/\n",
      "trial:  30-fish/0084/\n",
      "trial:  /30-fish/0115/\n",
      "trial:  /30-fish/0120/\n",
      "trial:  70-fish/0103/\n",
      "trial:  70-fish/0107/\n",
      "trial:  70-fish/0124/\n",
      "trial:  150-fish/\n"
     ]
    }
   ],
   "source": [
    "grid_frontbackdist = []\n",
    "grid_sidesidedist = []\n",
    "grid_groupstates = []\n",
    "grid_groupheading = []\n",
    "grid_orientations = []\n",
    "grid_tailcoords = []\n",
    "grid_positions = []\n",
    "grid_groupcentroid = []\n",
    "grid_lefteye = []\n",
    "grid_righteye = []\n",
    "\n",
    "tnum=0\n",
    "for tnum in range(len(trials)):\n",
    "    trial=trials[tnum]\n",
    "    print('trial: ',trial)\n",
    "    filedir=datadir+trial\n",
    "\n",
    "    filenames=np.sort(glob.glob(filedir+'*fov.h5'))\n",
    "\n",
    "    outname=filedir+'basicdata-v3.pklz'\n",
    "    [positions,orientations,tailcoords,lefteye,righteye,groupcentroid,groupheading,groupheadingxy,groupstates,pixelwidth,pixelheight,rotcoords] = pickle.load(gzip.open(outname,'rb'))\n",
    "    frontbackdist=rotcoords[:,:,0]\n",
    "    sidesidedist=rotcoords[:,:,1] \n",
    "    numsteps,numfish, _ = positions.shape\n",
    "    \n",
    "    grid_frontbackdist.append(frontbackdist)\n",
    "    grid_sidesidedist.append(sidesidedist)\n",
    "    grid_groupstates.append(groupstates)\n",
    "    grid_groupheading.append(groupheading)\n",
    "    grid_orientations.append(orientations)\n",
    "    grid_tailcoords.append(tailcoords)\n",
    "    grid_positions.append(positions)    \n",
    "    grid_groupcentroid.append(groupcentroid)\n",
    "    grid_lefteye.append(lefteye)\n",
    "    grid_righteye.append(righteye)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'data-grid.pklz'\n",
    "pickle.dump([grid_frontbackdist,grid_sidesidedist,grid_groupstates,grid_groupheading,grid_orientations,grid_tailcoords,grid_positions,grid_groupcentroid,grid_lefteye,grid_righteye],gzip.open(resultsdir+datafile,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate results for example case and save in condensed form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "savefile = 'distributions+exampledata.pkl'\n",
    "# processing_skipvalue = 5  # remember, I only kept every 5th one, for the detection calculations\n",
    "exampleframes = np.array([51339,56496,60123,379])\n",
    "exampleframes_short = np.round(exampleframes/processing_skipvalue).astype(int)  # close enough to the ones I chose originally, should be alright\n",
    "\n",
    "\n",
    "## Loop through and save the calculations needed in order to make the plot\n",
    "\n",
    "degreebins = np.linspace(0,1,200)\n",
    "degreevalues = (degreebins[1:]+degreebins[0:-1])/2\n",
    "distbins = np.linspace(0,500,120) \n",
    "distvalues = (distbins[1:]+distbins[0:-1])/2\n",
    "distributions1D = np.zeros((4,len(degreebins)-1))\n",
    "distributions1D_problow = np.zeros((4,len(degreebins)-1))\n",
    "distributions1D_probhigh = np.zeros((4,len(degreebins)-1))\n",
    "distributions1D_blind = np.zeros((4,len(degreebins)-1))\n",
    "exampledata = []\n",
    "\n",
    "# some functions for convenience, define outside loop\n",
    "def get1dhist(x):\n",
    "    return np.histogram(np.reshape(np.mean(x,axis=-1),-1),bins=degreebins, density=True)[0]\n",
    "def getsmooth1dhist(x):\n",
    "    kde = scipy.stats.gaussian_kde(np.reshape(np.mean(x,axis=-1),-1))\n",
    "    return kde.evaluate(degreevalues) \n",
    "\n",
    "\n",
    "histfn = getsmooth1dhist\n",
    "# histfn = get1dhist\n",
    "\n",
    "\n",
    "for case in range(4):    \n",
    "    print(case)\n",
    "    catcasedata = lambda x:  np.concatenate([g[::processing_skipvalue] for g in x[case*3:(case+1)*3]]) # keep inside loop\n",
    "    # these use processing_skip_value, so can directly compare with detection results\n",
    "    ssjoined = catcasedata(grid_sidesidedist)\n",
    "    fbjoined=catcasedata(grid_frontbackdist)\n",
    "    orientjoined=catcasedata(grid_orientations)\n",
    "    gcjoined = catcasedata(grid_groupcentroid)\n",
    "    # treat this one differently, becase the group heading has a length of 1 shorter\n",
    "    catcasedata_derivativedata = lambda x: np.concatenate([np.insert(g,0,0)[::processing_skipvalue] for g in x[case*3:(case+1)*3]]) # keep inside loop\n",
    "    groupheadingjoined=catcasedata_derivativedata(grid_groupheading)\n",
    "    numfish = ssjoined.shape[1]\n",
    "  \n",
    "    # save histogram data\n",
    "    distributions1D[case] = histfn(grid_allseen[case])\n",
    "    distributions1D_problow[case] = histfn(grid_allseen_problow[case])\n",
    "    distributions1D_probhigh[case] = histfn(grid_allseen_probhigh[case])\n",
    "    distributions1D_blind[case] = histfn(grid_allseen_blind[case])\n",
    "    distance = np.sqrt(np.reshape(ssjoined,-1)**2 + np.reshape(fbjoined,-1)**2)\n",
    "    \n",
    "    # example frame data and segments\n",
    "    step = exampleframes_short[case]\n",
    "    points = np.array([fbjoined[step,:],ssjoined[step,:]]).T\n",
    "    orients = orientjoined[step,:]\n",
    "    # need to rotate around the group heading axis\n",
    "    xrot = np.cos(groupheadingjoined[step])\n",
    "    yrot = -np.sin(groupheadingjoined[step])\n",
    "    rotatefn = lambda x:  np.dot([[xrot,-yrot],[yrot,xrot]],(x-gcjoined[step]).T).T\n",
    "    le_rot = rotatefn(catcasedata(grid_lefteye)[step])\n",
    "    re_rot = rotatefn(catcasedata(grid_righteye)[step])\n",
    "    tail_rot = rotatefn(catcasedata(grid_tailcoords)[step])\n",
    "    points_tp = rotatefn(catcasedata(grid_positions)[step])\n",
    "    fsegs = detection.fishmodel(points_tp,le_rot,re_rot,tail_rot)\n",
    "#     segments = np.reshape(fsegs,(-1,2,2))\n",
    "    seen = np.mean(grid_allseen[case][step],axis=-1)\n",
    "    seen_problow = np.mean(grid_allseen_problow[case][step],axis=-1)\n",
    "    seen_probhigh = np.mean(grid_allseen_probhigh[case][step],axis=-1)\n",
    "    seen_blind = np.mean(grid_allseen_blind[case][step],axis=-1)\n",
    "    exampledata.append([fsegs,points,orients-groupheadingjoined[step],le_rot,re_rot,tail_rot,seen,seen_problow,seen_probhigh,seen_blind])\n",
    "    \n",
    "\n",
    "d1D = [distributions1D,distributions1D_problow,distributions1D_probhigh,distributions1D_blind]\n",
    "pickle.dump([degreebins,distbins,d1D,exampledata], open(resultsdir+savefile,'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
